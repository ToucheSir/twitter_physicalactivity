---
title: "Twitter and Physical Activity"
output:
  html_notebook: default
  github_document: default
---
```{r message=FALSE}
library(foreign)
library(betareg)
library(ggplot2)
library(fitdistrplus)
library(logspline)
library(Hmisc)
library(knitr)
library(dplyr)
```

The compiled dataset contains a subset of US counties (names and FIPS codes).

The associated data for each county is as follows:

* All_Tweets: the total collected number of tweets from that county
* PA_Tweets: the number of tweets identified as physical activity-related
* Inactivity_Cases: TODO
* Inactivity_Percent: TODO
* Inactivity_Percent_AgeAdjusted: TODO
* Gini_Index: TODO
* Gini_Index_MoE: the margin of error of the Gini index estimate

```{r results='asis'}
# This helper will render legible tables in both RStudio and the generated markdown.
display <- function(x) {
  if (interactive()) (x)
  else kable(x)
}

all_data <- read.csv("data/all_data.csv")
display(head(all_data))
```

Not all counties in the dataset have tweet or physical activity data available, so we must filter those out.
We must also normalize the percentages (expressed here as a number /100) to values we can use for a beta distribution (i.e. 0-1)

```{r}
# Remove rows with missing values
cat('Rows in complete dataset: ', nrow(all_data), '\n')
cleaned_data <- na.omit(all_data)
cleaned_data <- cleaned_data[cleaned_data$Tweets.All >= cleaned_data$Tweets.PA,]
cat('Rows after cleaning: ', nrow(cleaned_data))

#cleaned_data$Tweets.PA.Log <- log1p(cleaned_data$Tweets.PA)
cleaned_data$Tweets.PA.Percent <- cleaned_data$Tweets.PA / cleaned_data$Tweets.All
cleaned_data$Inactivity.Percent <- cleaned_data$Inactivity.Percent / 100
cleaned_data$Inactivity.Ageadjusted <- cleaned_data$Inactivity.Ageadjusted / 100

display(head(arrange(cleaned_data, desc(Tweets.All))))
display(head(arrange(cleaned_data, desc(Tweets.PA))))

vars <- c(
  "Gini_Index.Estimate",
  "Tweets.PA",
  "Tweets.PA.Percent",
#  "Tweets.PA.Log",
  "Tweets.All",
  "Inactivity.Cases",
  "Inactivity.Percent",
  "Inactivity.Ageadjusted"
)
display(as.data.frame(do.call(cbind, lapply(cleaned_data[vars], summary))))
```

The count data are heavily right-skewed with notable outliers. This is partly attributable to the disparity in population between counties
(e.g. LA, the most populous county, has a similar relative magnitude of tweets)

```{r fig.width=20, fig.height=10}
par(mfrow=c(ceiling(length(vars) / 2), 2))
for (v in vars) {
  boxplot(cleaned_data[v], main = v, horizontal = TRUE)
}
```

```{r fig.width=20, fig.height=15}
par(mfrow=c(2, 2))
hist(cleaned_data$Inactivity.Percent)
descdist(cleaned_data$Inactivity.Percent)

hist(cleaned_data$Inactivity.Ageadjusted)
descdist(cleaned_data$Inactivity.Ageadjusted)

fit.beta1 <- fitdist(cleaned_data$Inactivity.Percent, "beta")
plot(fit.beta1)

fit.beta2 <- fitdist(cleaned_data$Inactivity.Ageadjusted, "beta")
plot(fit.beta2)
```

Correlation of variables:

```{r out.width=20}
results <- rcorr(as.matrix(cleaned_data[vars]), type = "pearson")
display(as.data.frame(results$r))
display(as.data.frame(results$P))
```

Correlation of variables:

```{r out.width=20}
results <- rcorr(as.matrix(cleaned_data[vars]), type = "spearman")
display(as.data.frame(results$r))
display(as.data.frame(results$P))
```

Comparing models:

```{r}
m1 <- betareg(Inactivity.Percent ~ Tweets.PA, data = cleaned_data)
summary(m1)

m2 <- update(m1, . ~ . + Gini_Index.Estimate)
summary(m2)

m3 <- update(m2, . ~ . + Tweets.PA:Gini_Index.Estimate)
summary(m3)

display(merge(AIC(m1, m2, m3), BIC(m1, m2, m3)))
```
```{r}
m1.aa <- betareg(Inactivity.Ageadjusted ~ Tweets.PA, data = cleaned_data)
summary(m1.aa)

m2.aa <- update(m1, . ~ . + Gini_Index.Estimate)
summary(m2.aa)

m3.aa <- update(m2, . ~ . + Tweets.PA:Gini_Index.Estimate)
summary(m3.aa)

display(merge(AIC(m1.aa, m2.aa, m3.aa), BIC(m1.aa, m2.aa, m3.aa)))
```

```{r fig.width=20, fig.height=15}
par(mfrow=c(2, 1))
scatter.smooth(cleaned_data$Tweets.PA, cleaned_data$Inactivity.Percent)
scatter.smooth(log1p(cleaned_data$Tweets.PA), cleaned_data$Inactivity.Percent)
```

```{r}
predict(m3, cleaned_data[cleaned_data$Geography == 'Madison County, New York',])
```
```{r}
#map_data <- cleaned_data[c('FIPS', 'Inactivity.Percent')]
#names(map_data) <- c('region', 'value')

#library(choroplethr)
#map_data$value <- cleaned_data$Tweets.PA / cleaned_data$Tweets.All * 100
#county_choropleth(map_data)

#map_data$value <- cleaned_data$Tweets.PA
#county_choropleth(map_data)

#map_data$value <- cleaned_data$Gini_Index.Estimate
#county_choropleth(map_data)

#map_data$value <- cleaned_data$Inactivity.Percent * 100
#county_choropleth(map_data, title = '\tPercentage of Physical Inactivity')

#map_data$value <- predict(m1, cleaned_data) * 100
#county_choropleth(map_data, title = '\tModel 1 Predictions')
#map_data$value <- predict(m2, cleaned_data) * 100
#county_choropleth(map_data, title = '\tModel 2 Predictions')
#map_data$value <- predict(m3, cleaned_data) * 100
#county_choropleth(map_data, title = '\tModel 3 Predictions')

#map_data$value <- cleaned_data$Inactivity.Ageadjusted * 100
#county_choropleth(map_data, title = '\tPercentage of Physical Inactivity (Age-adjusted)')

#map_data$value <- predict(m1.aa, cleaned_data) * 100
#county_choropleth(map_data, title = '\tModel 1 Predictions')
#map_data$value <- predict(m2.aa, cleaned_data) * 100
#county_choropleth(map_data, title = '\tModel 2 Predictions')
#map_data$value <- predict(m3.aa, cleaned_data) * 100
#county_choropleth(map_data, title = '\tModel 3 Predictions')
```