---
title: "Twitter and Physical Activity"
output:
  github_document: default
  html_notebook: default
---
```{r message=FALSE}
library(foreign)
library(betareg)
library(ggplot2)
library(fitdistrplus)
library(logspline)
library(Hmisc)
library(knitr)
```

The compiled dataset contains a subset of US counties (names and FIPS codes).

The associated data for each county is as follows:

* All_Tweets: the total collected number of tweets from that county
* PA_Tweets: the number of tweets identified as physical activity-related
* Inactivity_Cases: TODO
* Inactivity_Percent: TODO
* Inactivity_Percent_AgeAdjusted: TODO
* Gini_Index: TODO
* Gini_Index_MoE: the margin of error of the Gini index estimate

```{r results='asis'}
# This helper will render legible tables in both RStudio and the generated markdown.
display <- function(x) {
  if (interactive()) (x)
  else kable(x)
}

all_data <- read.csv("all_data_mmsa.csv")
display(head(all_data))
```

Not all counties in the dataset have tweet or physical activity data available, so we must filter those out.
We must also normalize the percentages (expressed here as a number /100) to values we can use for a beta distribution (i.e. 0-1)

```{r}
# Remove rows with missing values
cleaned_data <- na.omit(all_data)
cleaned_data$Tweets.PA.Log <- log1p(cleaned_data$Tweets.PA)
cleaned_data$PA.Total <- cleaned_data$PA.Active + cleaned_data$PA.Inactive
cleaned_data$PA.Percent.Active <- cleaned_data$PA.Active / cleaned_data$PA.Total
cleaned_data$PA.Percent.Inactive <- cleaned_data$PA.Inactive / cleaned_data$PA.Total

vars <- c(
  "Gini_Index.Estimate",
  "Tweets.PA",
  "Tweets.All",
  "PA.Active",
  "PA.Inactive",
  "PA.Percent.Active",
  "PA.Percent.Inactive"
)
display(as.data.frame(do.call(cbind, lapply(cleaned_data[vars], summary))))
```

The count data are heavily right-skewed with notable outliers. This is partly attributable to the disparity in population between counties
(e.g. LA, the most populous county, has a similar relative magnitude of tweets)

```{r fig.width=20, fig.height=8}
par(mfrow=c(ceiling(length(vars) / 2), 2))
for (v in vars) {
  boxplot(cleaned_data[v], main = v, horizontal = TRUE)
}
```

```{r fig.width=20, fig.height=15}
par(mfrow=c(2, 2))
hist(cleaned_data$PA.Percent.Active)
descdist(cleaned_data$PA.Percent.Active)

hist(cleaned_data$PA.Percent.Inactive)
descdist(cleaned_data$PA.Percent.Inactive)

fit.beta1 <- fitdist(cleaned_data$PA.Percent.Active, "beta")
plot(fit.beta1)

fit.beta2 <- fitdist(cleaned_data$PA.Percent.Inactive, "beta")
plot(fit.beta2)
```

Correlation of variables:

```{r out.width=20}
results <- rcorr(as.matrix(cleaned_data[vars]), type = "pearson")
display(as.data.frame(results$r))
display(as.data.frame(results$P))
```

Comparing models:

```{r}
m1 <- betareg(PA.Percent.Inactive ~ Tweets.PA, data = cleaned_data)
summary(m1)

m2 <- update(m1, . ~ . + Gini_Index.Estimate)
summary(m2)

m3 <- update(m2, . ~ . + Tweets.PA:Gini_Index.Estimate)

m4 <- betareg(PA.Percent.Inactive ~ Tweets.PA.Log, data = cleaned_data)
summary(m4)

m5 <- update(m4, . ~ . + Gini_Index.Estimate)
summary(m5)

m6 <- update(m5, . ~ . + Tweets.PA:Gini_Index.Estimate)
summary(m6)

# AIC(m.beta1, m.beta2, m.beta3)
display(AIC(m1, m2, m3, m4, m5, m6, k = log(nrow(cleaned_data))))
```

```{r}
trunc_data <- cleaned_data[cleaned_data$Tweets.All > median(cleaned_data$Tweets.All),]
results <- rcorr(as.matrix(trunc_data[vars]), type = "pearson")
display(as.data.frame(results$r))
display(as.data.frame(results$P))
```

```{r fig.width=20, fig.height=15}
par(mfrow=c(2, 1))
scatter.smooth(cleaned_data$Tweets.PA, cleaned_data$PA.Percent.Inactive)
scatter.smooth(cleaned_data$Tweets.PA.Log, cleaned_data$PA.Percent.Inactive)
```

```{r}
predict(m4, data.frame(Tweets.PA.Log = log(23)))
```

